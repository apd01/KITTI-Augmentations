{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71e5723d",
   "metadata": {},
   "source": [
    "# Generate augmentations and split files\n",
    "#### 12 augmentations\n",
    "#### 1 original\n",
    "#### Affine transform: Both original image and depth map must be augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "093e56f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from augmentations import augmentation_choices, transform_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e1d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows will accept '/' as separator\n",
    "split_file = 'kitti_eigen_test.txt'\n",
    "input_prefix_path = \"E:/Thesis_Datasets/kitti_full/\"\n",
    "input_depth_folder = 'val'\n",
    "output_prefix_path = \"E:/Thesis_Datasets/Augmented_Images/\"\n",
    "output_image_folder = \"Data/\"\n",
    "output_depth_folder = \"Depth/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c057c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32aeb31a36874117898e3b7a7841c784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting input files...:   0%|          | 0/652 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid images:  652\n"
     ]
    }
   ],
   "source": [
    "valid_image_count = 0\n",
    "with open(split_file) as f:\n",
    "    for line in tqdm(f, desc=\"Counting input files...\", total=652):\n",
    "        img_name = line.strip().split(\" \")[0]\n",
    "        img_name = osp.join(input_prefix_path, img_name)\n",
    "        depth_file = line.strip().split(\" \")[1]\n",
    "        depth_map = osp.join(input_prefix_path, input_depth_folder, depth_file)\n",
    "\n",
    "        if not osp.isfile(depth_map):\n",
    "            depth_map = osp.join(input_prefix_path, 'train', depth_file)\n",
    "        if osp.isfile(img_name) and osp.isfile(depth_map):\n",
    "            valid_image_count += 1\n",
    "        \n",
    "print(\"Total valid images: \", valid_image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c83bf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "gaussian\n",
      "localvar\n",
      "poisson\n",
      "salt\n",
      "pepper\n",
      "s&p\n",
      "speckle\n",
      "affine\n",
      "rain\n",
      "shadow\n",
      "flare\n",
      "snow\n"
     ]
    }
   ],
   "source": [
    "for aug in augmentation_choices:\n",
    "    print(aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3334f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation_choices = ['gaussian', 'affine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f0fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "with open(split_file) as f:\n",
    "    for line in f:\n",
    "        count += 1\n",
    "        img_name = line.strip().split(\" \")[0]\n",
    "        img_name = osp.join(input_prefix_path, img_name)\n",
    "        depth_file = line.strip().split(\" \")[1]\n",
    "        depth_map = osp.join(input_prefix_path, input_depth_folder, depth_file)\n",
    "#         scale=(1.1, 1.1)\n",
    "#         rotation=random.uniform(0.00, 0.0)\n",
    "    #         shear=random.uniform(0.0, 0.0)\n",
    "\n",
    "            scale=None\n",
    "            rotation=None\n",
    "            shear=None\n",
    "\n",
    "            original_depth = cv2.imread(depth_map, cv2.IMREAD_UNCHANGED)\n",
    "        augmented_depth = transform_image(aug, original_depth, scale, rotation, shear)\n",
    "        \n",
    "        print(f\"Dimensions of depth map: \\t{original_depth.shape}\")\n",
    "        print(f\"Max of depth map: \\t{original_depth.max()}\")\n",
    "        print(f\"Type of max of depth map: {type(original_depth.max())}\")\n",
    "        print(f\"Dimensions of transformed depth: {augmented_depth.shape}\")\n",
    "        print(f\"Max of transformed depth map: {augmented_depth.max()}\")\n",
    "        \n",
    "\n",
    "        cv2.imwrite(osp.join(\"./\" + img_name.split('/')[-1]), augmented_depth)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b9f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = osp.normpath(osp.join(input_prefix_path, input_depth_folder, depth_file)).replace('\\\\', '/')\n",
    "\n",
    "# print(range(len(filepath.split('/'))-1))\n",
    "print(filepath)\n",
    "\n",
    "for i in range(len(filepath.split('/'))-1):\n",
    "    current_dir = osp.join('', *(filepath.split('/')[:i+1]))\n",
    "    print(f\"current directory: {current_dir}\")\n",
    "    print(f\"exists: {osp.isdir(current_dir)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a730d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_good_pixels = 0\n",
    "for i in range(original_depth.shape[0]):\n",
    "    for j in range(original_depth.shape[1]):\n",
    "        if(original_depth[i][j] == augmented_depth[i][j]):\n",
    "            count_good_pixels += 1\n",
    "print(count)\n",
    "print(original_depth[200][115:120])\n",
    "print(augmented_depth[200][115:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c675808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subdir(path):\n",
    "    filepath = osp.normpath(path).replace('\\\\', '/')\n",
    "                \n",
    "    for i in range(len(filepath.split('/'))):\n",
    "        current_dir = osp.join('', *(filepath.split('/')[:i+1]))            \n",
    "     \n",
    "        if not osp.isdir(current_dir):\n",
    "            try:\n",
    "#                 print(f\"Making {current_dir}\")\n",
    "                os.mkdir(current_dir)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Failed to make {current_dir}. Make sure the parent folder exists.\")                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc39a8dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'depth_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-483ea60ac84a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdepth_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'depth_split' is not defined"
     ]
    }
   ],
   "source": [
    "depth_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb03d730",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d0b60ba90c48ec89216292cb2a4035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Augmenting input files...:   0%|          | 0/652 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total augmented files: 652\n",
      "Total invalid files: 45\n"
     ]
    }
   ],
   "source": [
    "invalid_image_count = 0\n",
    "valid_image_count = 0\n",
    "image_data = []\n",
    "\n",
    "with open(split_file) as f:\n",
    "    for line in tqdm(f, desc=\"Augmenting input files...\", total=652):\n",
    "        img_split = line.strip().split(\" \")[0]\n",
    "        img_filename = osp.join(input_prefix_path, img_split)\n",
    "        depth_postfix = line.strip().split(\" \")[1]\n",
    "        depth_filename = osp.join(input_prefix_path, input_depth_folder, depth_postfix)\n",
    "        \n",
    "        if not osp.isfile(depth_filename):\n",
    "            depth_filename = osp.join(input_prefix_path, 'train', depth_postfix)\n",
    "\n",
    "        if osp.isfile(img_filename) and osp.isfile(depth_filename):\n",
    "            valid_image_count += 1\n",
    "\n",
    "            # Ensure the folder exists\n",
    "            make_subdir(osp.join(output_prefix_path, output_depth_folder, osp.join('', *depth_postfix.split('/')[:-1])))\n",
    "\n",
    "            #   Copy depth map\n",
    "            shutil.copy(depth_filename,\n",
    "                        osp.join(output_prefix_path, \n",
    "                                 output_depth_folder, \n",
    "                                 osp.join('', *depth_postfix.split('/')[:-1]), depth_filename.split('/')[-1]))\n",
    "\n",
    "            #   For each augmentation type:\n",
    "            for aug in augmentation_choices:\n",
    "                if aug == None:\n",
    "                    aug = \"None\"\n",
    "                \n",
    "                make_subdir(osp.join(output_prefix_path, output_image_folder, aug, *img_split.split('/')[:-1]))\n",
    "\n",
    "                # For all other augmentation types:          \n",
    "                if aug != 'affine':\n",
    "                    img = transform_image(aug, cv2.imread(img_filename))\n",
    "                    # todo: fix list\n",
    "                    # Insert [rgb_file, depth_prefix, augmentation_type] into list\n",
    "                    image_data.append([osp.join(output_image_folder, \n",
    "                                                aug,\n",
    "                                                osp.join('', *img_split.split('/')[:-1]).replace('\\\\', '/'),\n",
    "                                                img_filename.split('/')[-1]\n",
    "                                               ),\n",
    "                                       osp.join(output_depth_folder,\n",
    "                                                osp.join('', *depth_postfix.split('/')[:-1]).replace('\\\\', '/'),\n",
    "                                                depth_postfix.split('/')[-1]),\n",
    "                                       aug])\n",
    "                    \n",
    "                # if aug = affine, depth map needs to be augmented with the same scale, rotation and shear\n",
    "                else:\n",
    "                    make_subdir(osp.join(output_prefix_path, output_depth_folder, aug, *depth_postfix.split('/')[:-1]))\n",
    "\n",
    "                    scale=(1.1, 1.1)\n",
    "                    rotation=random.uniform(-0.05, 0.05)\n",
    "                    shear=random.uniform(-0.1, 0.1)\n",
    "\n",
    "                    img = transform_image(aug, cv2.imread(img_filename), scale, rotation, shear)\n",
    "                    \n",
    "                    # Note: Read as UNCHANGED (ie grayscale), otherwise imwrite will save RGB channels\n",
    "                    augmented_depth = transform_image(aug, cv2.imread(depth_filename, cv2.IMREAD_UNCHANGED), scale, rotation, shear)\n",
    "\n",
    "                    # todo: change write location\n",
    "                    # Save transformed depth map in Depth/affine/xxxxxxx_affine.png\n",
    "                    cv2.imwrite(osp.join(output_prefix_path, \n",
    "                                     output_depth_folder, \n",
    "                                     aug,\n",
    "                                     osp.join('', *depth_postfix.split('/')[:-1]).replace('\\\\', '/'),\n",
    "                                     img_filename[img_filename.rfind('/')+1:-4] + \"_affine.png\"),\n",
    "                                augmented_depth)\n",
    "                    \n",
    "                    # todo: fix list\n",
    "                    # Insert  [rgb_file, \n",
    "                    #          depth_split, \n",
    "                    #          augmentation_type] \n",
    "                    #   into list\n",
    "                    image_data.append([osp.join(output_image_folder, \n",
    "                                                aug, \n",
    "                                                osp.join('', *img_split.split('/')[:-1]).replace('\\\\', '/'), \n",
    "                                                img_filename.split('/')[-1]\n",
    "                                               ),\n",
    "                                       osp.join(output_depth_folder, \n",
    "                                                aug,\n",
    "                                                osp.join('', *depth_postfix.split('/')[:-1]).replace('\\\\', '/'),\n",
    "                                                depth_filename.split('/')[-1][:-4] + \"_affine.png\"),\n",
    "                                       aug]\n",
    "                                     )\n",
    "                    \n",
    "                # todo: change write location\n",
    "                # Save augmented RGB file with new name in /<augmentation_type>/ folder\n",
    "                cv2.imwrite(\n",
    "                    osp.join(output_prefix_path, \n",
    "                                     output_image_folder, \n",
    "                                     aug, \n",
    "                                     osp.join('', *img_split.split('/')[:-1]).replace('\\\\', '/'),\n",
    "                                     img_filename.split('/')[-1]),\n",
    "                    img\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            invalid_image_count += 1\n",
    "\n",
    "\n",
    "print(f\"Total augmented files: {valid_image_count}\")\n",
    "print(f\"Total invalid files: {invalid_image_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c58cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a25b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "osp.join(output_prefix_path, output_depth_folder, aug, *depth_split.split('/')[:-1])\n",
    "# make_subdir(test_dir)\n",
    "# cv2.imwrite(test_dir, augmented_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4060c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "osp.join('', *img_split.split('/')[:-1]).replace('\\\\', '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e388f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_split)\n",
    "print(depth_filename)\n",
    "print(img_split.split('/')[:-1])\n",
    "print(depth_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb9d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(image_data_df['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8218514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "osp.join(output_prefix_path, \n",
    "                                     output_image_folder, \n",
    "                                     aug, \n",
    "                                     img_name.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c7b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(osp.join(output_prefix_path, \n",
    "#                                      output_image_folder, \n",
    "#                                      aug, \n",
    "#                                      img_name.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_data_df['image'][0].replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87822c0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>depth</th>\n",
       "      <th>augmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/None/2011_09_26/2011_09_26_drive_0002_syn...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/gaussian/2011_09_26/2011_09_26_drive_0002...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>gaussian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/localvar/2011_09_26/2011_09_26_drive_0002...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>localvar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/poisson/2011_09_26/2011_09_26_drive_0002_...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/salt/2011_09_26/2011_09_26_drive_0002_syn...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data/pepper/2011_09_26/2011_09_26_drive_0002_s...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>pepper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data/s&amp;p/2011_09_26/2011_09_26_drive_0002_sync...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>s&amp;p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data/speckle/2011_09_26/2011_09_26_drive_0002_...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>speckle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data/affine/2011_09_26/2011_09_26_drive_0002_s...</td>\n",
       "      <td>Depth/affine/2011_09_26_drive_0002_sync/proj_d...</td>\n",
       "      <td>affine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data/rain/2011_09_26/2011_09_26_drive_0002_syn...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data/shadow/2011_09_26/2011_09_26_drive_0002_s...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>shadow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data/flare/2011_09_26/2011_09_26_drive_0002_sy...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>flare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data/snow/2011_09_26/2011_09_26_drive_0002_syn...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data/None/2011_09_26/2011_09_26_drive_0002_syn...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data/gaussian/2011_09_26/2011_09_26_drive_0002...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>gaussian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data/localvar/2011_09_26/2011_09_26_drive_0002...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>localvar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data/poisson/2011_09_26/2011_09_26_drive_0002_...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>poisson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data/salt/2011_09_26/2011_09_26_drive_0002_syn...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data/pepper/2011_09_26/2011_09_26_drive_0002_s...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>pepper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data/s&amp;p/2011_09_26/2011_09_26_drive_0002_sync...</td>\n",
       "      <td>Depth/2011_09_26_drive_0002_sync/proj_depth/gr...</td>\n",
       "      <td>s&amp;p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                image  \\\n",
       "0   Data/None/2011_09_26/2011_09_26_drive_0002_syn...   \n",
       "1   Data/gaussian/2011_09_26/2011_09_26_drive_0002...   \n",
       "2   Data/localvar/2011_09_26/2011_09_26_drive_0002...   \n",
       "3   Data/poisson/2011_09_26/2011_09_26_drive_0002_...   \n",
       "4   Data/salt/2011_09_26/2011_09_26_drive_0002_syn...   \n",
       "5   Data/pepper/2011_09_26/2011_09_26_drive_0002_s...   \n",
       "6   Data/s&p/2011_09_26/2011_09_26_drive_0002_sync...   \n",
       "7   Data/speckle/2011_09_26/2011_09_26_drive_0002_...   \n",
       "8   Data/affine/2011_09_26/2011_09_26_drive_0002_s...   \n",
       "9   Data/rain/2011_09_26/2011_09_26_drive_0002_syn...   \n",
       "10  Data/shadow/2011_09_26/2011_09_26_drive_0002_s...   \n",
       "11  Data/flare/2011_09_26/2011_09_26_drive_0002_sy...   \n",
       "12  Data/snow/2011_09_26/2011_09_26_drive_0002_syn...   \n",
       "13  Data/None/2011_09_26/2011_09_26_drive_0002_syn...   \n",
       "14  Data/gaussian/2011_09_26/2011_09_26_drive_0002...   \n",
       "15  Data/localvar/2011_09_26/2011_09_26_drive_0002...   \n",
       "16  Data/poisson/2011_09_26/2011_09_26_drive_0002_...   \n",
       "17  Data/salt/2011_09_26/2011_09_26_drive_0002_syn...   \n",
       "18  Data/pepper/2011_09_26/2011_09_26_drive_0002_s...   \n",
       "19  Data/s&p/2011_09_26/2011_09_26_drive_0002_sync...   \n",
       "\n",
       "                                                depth augmentation  \n",
       "0   Depth/2011_09_26_drive_0002_sync/proj_depth/gr...         None  \n",
       "1   Depth/2011_09_26_drive_0002_sync/proj_depth/gr...     gaussian  \n",
       "2   Depth/2011_09_26_drive_0002_sync/proj_depth/gr...     localvar  \n",
       "3   Depth/2011_09_26_drive_0002_sync/proj_depth/gr...      poisson  \n",
       "4   Depth/2011_09_26_drive_0002_sync/proj_depth/gr...         salt  \n",
       "5   Depth/2011_09_26_drive_0002_sync/proj_depth/gr...       pepper  \n",
       "6   Depth/2011_09_26_drive_0002_sync/proj_depth/gr...          s&p  \n",
       "7   Depth/2011_09_26_drive_0002_sync/proj_depth/gr...      speckle  \n",
       "8   Depth/affine/2011_09_26_drive_0002_sync/proj_d...       affine  \n",
       "9   Depth/2011_09_26_drive_0002_sync/proj_depth/gr...         rain  \n",
       "10  Depth/2011_09_26_drive_0002_sync/proj_depth/gr...       shadow  \n",
       "11  Depth/2011_09_26_drive_0002_sync/proj_depth/gr...        flare  \n",
       "12  Depth/2011_09_26_drive_0002_sync/proj_depth/gr...         snow  \n",
       "13  Depth/2011_09_26_drive_0002_sync/proj_depth/gr...         None  \n",
       "14  Depth/2011_09_26_drive_0002_sync/proj_depth/gr...     gaussian  \n",
       "15  Depth/2011_09_26_drive_0002_sync/proj_depth/gr...     localvar  \n",
       "16  Depth/2011_09_26_drive_0002_sync/proj_depth/gr...      poisson  \n",
       "17  Depth/2011_09_26_drive_0002_sync/proj_depth/gr...         salt  \n",
       "18  Depth/2011_09_26_drive_0002_sync/proj_depth/gr...       pepper  \n",
       "19  Depth/2011_09_26_drive_0002_sync/proj_depth/gr...          s&p  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure we are using linux-style '/' instead of windows '\\' or '\\\\'\n",
    "\n",
    "image_data_df = pd.DataFrame(image_data, columns=['image', 'depth', 'augmentation'])\n",
    "image_data_df['image'] = image_data_df['image'].apply(lambda x: x.replace('\\\\', r'/'))\n",
    "image_data_df['depth'] = image_data_df['depth'].apply(lambda x: x.replace('\\\\', r'/'))\n",
    "image_data_df.head(20)\n",
    "# image_data_df.depth[8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f93d4b1",
   "metadata": {},
   "source": [
    "Create a split_file_<aug>.txt for each augmentation type, and save the full dataframe as a pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae82c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "for aug in augmentation_choices[1:]:\n",
    "    subset = image_data_df.loc[image_data_df.augmentation == aug]\n",
    "    subset[['image', 'depth']].to_csv('E:\\Thesis_Datasets\\Augmented_Images\\split_file_'+aug+'.txt', sep=' ', index=False, header=False)\n",
    "image_data_df.to_pickle('image_data_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b183f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = image_data_df.loc[image_data_df.augmentation == 'None']\n",
    "subset[['image', 'depth']].to_csv('E:\\Thesis_Datasets\\Augmented_Images\\split_file_'+'None.txt', sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f2504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
