{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "093e56f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from augmentations import augmentation_choices, transform_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2162ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell, define a function to save the NEW split files\n",
    "# Save a split file for EACH augmentation\n",
    "# and one for the whole augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c675808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subdir(subdir):\n",
    "    if not osp.isdir(subdir):\n",
    "        try:\n",
    "            os.mkdir(subdir)\n",
    "        except FileNotFoundError:\n",
    "            print(\"Make sure the parent folder exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb03d730",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50014a6f52f0479eb6762da88078cd3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Augmenting input files...:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 161 input files\n"
     ]
    }
   ],
   "source": [
    "split_file = 'kitti_eigen_test.txt'\n",
    "input_prefix_path = \"E:\\Thesis_Datasets\\\\kitti_full\\\\\"\n",
    "input_depth_dir = 'val'\n",
    "valid_image_count = 0\n",
    "img_infos = []\n",
    "output_prefix_path = \"E:\\Thesis_Datasets\\\\Augmented_Images\\\\\"\n",
    "output_image_folder = \"Data\\\\\"\n",
    "output_depth_folder = \"Depth\\\\\"\n",
    "\n",
    "with open(split_file) as f:\n",
    "    for line in tqdm(f, desc=\"Augmenting input files...\", total=697):\n",
    "        img_name = line.strip().split(\" \")[0]\n",
    "        img_name = osp.join(input_prefix_path, img_name)\n",
    "        depth_file = line.strip().split(\" \")[1]\n",
    "        depth_map = osp.join(input_prefix_path, input_depth_dir, depth_file)\n",
    "\n",
    "        if osp.isfile(img_name) and osp.isfile(depth_map):\n",
    "            valid_image_count += 1\n",
    "\n",
    "            # Ensure the folder exists\n",
    "            make_subdir(osp.join(output_prefix_path, output_depth_folder))\n",
    "\n",
    "            #   Copy depth map\n",
    "            shutil.copy(depth_map,\n",
    "                        osp.join(output_prefix_path, output_depth_folder, depth_map.split('/')[-1]))\n",
    "\n",
    "            #   For each augmentation type:\n",
    "            for aug in augmentation_choices:\n",
    "                make_subdir(osp.join(output_prefix_path, output_image_folder, aug))\n",
    "\n",
    "                # if aug = affine, depth map needs to be augmented with the same scale, rotation and shear\n",
    "                if aug == 'affine':\n",
    "                    make_subdir(osp.join(output_prefix_path, output_depth_folder, aug))\n",
    "\n",
    "                    scale=(1.1, 1.1)\n",
    "                    rotation=random.uniform(-0.05, 0.05)\n",
    "                    shear=random.uniform(-0.1, 0.1)\n",
    "\n",
    "                    img = transform_image(aug, cv2.imread(img_name), scale, rotation, shear)\n",
    "                    augmented_depth = transform_image(aug, cv2.imread(depth_map), scale, rotation, shear)\n",
    "\n",
    "                    # Save transformed depth map in Depth/affine/xxxxxxx_affine.png\n",
    "                    cv2.imwrite(osp.join(output_prefix_path, \n",
    "                                     output_depth_folder, \n",
    "                                     aug, \n",
    "                                     img_name[img_name.rfind('/')+1:-4] + \"_affine.png\"),\n",
    "                                augmented_depth)\n",
    "                    # TODO: insert [rgb_file, depth_file, augmentation_type] into LIST\n",
    "                    \n",
    "                else:\n",
    "                    img = transform_image(aug, cv2.imread(img_name))\n",
    "                    # insert [rgb_file, depth_file, augmentation_type] into LIST\n",
    "                    \n",
    "                # Save file with new name in /<augmentation_type>/ folder\n",
    "                cv2.imwrite(osp.join(output_prefix_path, \n",
    "                                     output_image_folder, \n",
    "                                     aug, \n",
    "                                     img_name.split('/')[-1]),\n",
    "                            img)\n",
    "\n",
    "print(f\"Total: {valid_image_count} input files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec5da618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valid_image_count is 161. Need to figure out why.\n",
    "valid_image_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
